{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for page request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url) :\n",
    "  page = requests.get(url)\n",
    "  soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "  soup_content = soup.find(\"div\", class_= \"latest--news\")\n",
    "  return soup_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class News:\n",
    "  def __init__(self, judul, narasi, tanggal, sumber, kategori, penulis) :\n",
    "    self.judul = judul\n",
    "    self.narasi = narasi\n",
    "    self.tanggal = tanggal\n",
    "    self.sumber = sumber\n",
    "    self.kategori = kategori\n",
    "    self.penulis = penulis\n",
    "  \n",
    "  def __str__(self) :\n",
    "    return f\"\"\"\n",
    "    {{  \n",
    "      Judul : {self.judul},\\n\n",
    "      Narasi : {self.narasi},\\n\n",
    "      Tanggal : {self.tanggal},\\n\n",
    "      Sumber : {self.sumber}, \\n\n",
    "      Kategori : {self.kategori}, \\n\n",
    "      Penulis : {self.penulis}\\n\n",
    "    }}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to replace \\<br> with \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_breaks(element) :\n",
    "  for br in element.find_all(\"br\"):\n",
    "    br.replace_with(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get each news' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_attributes(link) :\n",
    "  # fetch link\n",
    "  get_url = requests.get(link)\n",
    "  news_soup = BeautifulSoup(get_url.text, \"html\")\n",
    "\n",
    "  # judul\n",
    "  judul = news_soup.find(\"h1\", class_=\"read__title\")\n",
    "  if judul :\n",
    "    judul = judul.text.strip()\n",
    "  else :\n",
    "    judul = \"\"\n",
    "  \n",
    "  # narasi\n",
    "  [strong.decompose() for strong in news_soup.find_all(\"strong\")]\n",
    "\n",
    "  # decompose elements after \"EndOfArticle\"\n",
    "  end_of_article = news_soup.find(\"div\", id=\"EndOfArticle\")\n",
    "  if end_of_article :\n",
    "    end_of_article.find_next_sibling().decompose()\n",
    "  \n",
    "  narasi_content = news_soup.find(\"div\", class_=\"read__content\")\n",
    "  narasi = \"\"\n",
    "  if narasi_content :\n",
    "    narasi = narasi_content.find(\"div\", class_=\"clearfix\")\n",
    "  if narasi :\n",
    "    narasi = narasi.text.strip()\n",
    "  else :\n",
    "    narasi = \"\"\n",
    "\n",
    "  # tanggal\n",
    "  tanggal = news_soup.find(\"div\", class_=\"read__time\")\n",
    "  tanggal.find(\"a\").decompose()\n",
    "  if tanggal :\n",
    "    tanggal = tanggal.text.strip()\n",
    "  else : tanggal = \"\"\n",
    "\n",
    "  # sumber\n",
    "  sumber = \"kompas\" \n",
    "\n",
    "  # kategori\n",
    "  breadcrumb_all = news_soup.find_all(\"li\", class_=\"breadcrumb__item\")\n",
    "  kategori = breadcrumb_all[len(breadcrumb_all)-1].find(attrs={\"itemprop\" : \"name\"})\n",
    "\n",
    "  if kategori :\n",
    "    kategori = kategori.text.strip()\n",
    "  else : kategori = \"\"\n",
    "\n",
    "  # # penulis\n",
    "  penulis = news_soup.find(\"div\", class_=\"credit-title-name\")\n",
    "  if penulis :\n",
    "    penulis = penulis.text\n",
    "  else : penulis = \"\"\n",
    "  \n",
    "  return News(judul, narasi, tanggal, sumber, kategori, penulis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract individual news' link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_individual_link(element) :\n",
    "  articles = element.find_all(\"div\", class_=\"article__list clearfix\")\n",
    "  links = []\n",
    "  for article in articles :\n",
    "    link = article.find(\"a\", class_=\"article__link\").get(\"href\")\n",
    "    links.append(link)\n",
    "  return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe() :\n",
    "  columns = [\"judul\", \"narasi\", \"tanggal\", \"sumber\", \"kategori\", \"penulis\"]\n",
    "  df = pd.DataFrame(columns = columns)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to insert all news attributes to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_news(df, news) :\n",
    "  new_row = {\n",
    "    \"judul\" : news.judul,\n",
    "    \"narasi\" : news.narasi,\n",
    "    \"tanggal\" : news.tanggal,\n",
    "    \"sumber\" : news.sumber,\n",
    "    \"kategori\" : news.kategori,\n",
    "    \"penulis\" : news.penulis\n",
    "  }\n",
    "  df.loc[len(df)] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create list of dates starting from start_date to end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_list(start_date, end_date) :\n",
    "  return [quote(date.strftime(\"%Y-%m-%d\"), safe=\"\") for date in pd.date_range(start=start_date, end=end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to download CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def download_csv(df) :\n",
    "  file_path_name = r'C:/Users/Acer/Desktop/Skripsi/Code/program/kompas-3.csv'\n",
    "  if os.path.exists(file_path_name) :\n",
    "    raise FileExistsError(f\"The file already exists\")\n",
    "  else :\n",
    "    df.to_csv(file_path_name, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe()\n",
    "for date in create_date_list(\"2023-01-01\",\"2023-08-31\"):\n",
    "  page_content = get_content(f\"https://news.kompas.com/search/{date}\")\n",
    "  news_links = extract_individual_link(page_content)\n",
    "  for news_link in news_links :\n",
    "    attr = get_news_attributes(news_link)\n",
    "    insert_news(df, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_csv(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
